{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# set the subset of the data to use\n",
    "subset = 1\n",
    "# load the data\n",
    "data = json.load(open('../data/subsets/visdial_1.0_train_' +\n",
    "                 str(subset) + 'percent_subset.json'))['data']\n",
    "# load the dialogs\n",
    "dialogs = data['dialogs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "'''Load the GAP output of the History Graphs Batch'''\n",
    "with open('../embeddings/history/'+ str(subset) +'/history_batch_GAP.pkl', 'rb') as f:\n",
    "    history_batch_GAP = pickle.load(f)\n",
    "\n",
    "'''Load the GAP output of the Question Graphs'''\n",
    "with open('../embeddings/questions/'+ str(subset) +'/question_GAP.pkl', 'rb') as f:\n",
    "    question_GAP = pickle.load(f)\n",
    "\n",
    "'''Load the GAP output of the Image Graphs'''\n",
    "with open('../embeddings/images/instance/'+ str(subset) +'/image_GAP.pkl', 'rb') as f:\n",
    "    image_GAP = pickle.load(f)\n",
    "\n",
    "'''Load the Answer Embeddings'''\n",
    "with open('../embeddings/answers/' + str(subset) + '/answer_embeddings.pkl', 'rb') as f:\n",
    "    answer_embeddings = []\n",
    "    while True:\n",
    "        try:\n",
    "            answer_embeddings.append(pickle.load(f))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1233/1233 [00:00<00:00, 10989.47it/s]\n"
     ]
    }
   ],
   "source": [
    "'''For each <dialog> entry, we obtain the:\n",
    "    1. 10 questions from the <dialog rounds>\n",
    "    2. Copy the image 10 times from the <dialog rounds> since the image is the same for all rounds'''\n",
    "from tqdm import tqdm\n",
    "\n",
    "question_batch_GAP = []\n",
    "image_batch_GAP = []\n",
    "\n",
    "for dialog in tqdm(dialogs):\n",
    "    # get the image (the index of the image is the same as the index of the dialog); what the image ID contains is the reference to the image from COCO\n",
    "    image_id_dialog = image_GAP[dialogs.index(dialog)]\n",
    "    # copy the image 10 times\n",
    "    image_id_dialog = [image_id_dialog] * 10\n",
    "    # append the image to the image batch\n",
    "    image_batch_GAP.append(image_id_dialog)\n",
    "\n",
    "    # question gap for this dialog\n",
    "    question_GAP_dialog = []\n",
    "    # get the questions\n",
    "    for round in dialog['dialog']:\n",
    "        # get the question\n",
    "        question_GAP_dialog.append(question_GAP[round['question']])\n",
    "    # append the questions to the question batch\n",
    "    question_batch_GAP.append(question_GAP_dialog)\n",
    "\n",
    "'''Save the question GAP embeddings'''\n",
    "with open('../embeddings/fusion/question_GAP_batch_control' + str(subset) + '.pkl', 'wb') as f:\n",
    "    pickle.dump(question_batch_GAP, f)\n",
    "\n",
    "'''Save the image GAP embeddings'''\n",
    "with open('../embeddings/fusion/image_GAP_batch_control' + str(subset) + '.pkl', 'wb') as f:\n",
    "    pickle.dump(image_batch_GAP, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('gnnVD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:58:50) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0f314d012c094e500b437d772ea9d63f13832a9dbf30d5ab8fe744ae8c413d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
