{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['both surfboards are white',\n",
       " 'there is some sort of awning in the foreground',\n",
       " 'i think so, kind of hard to see',\n",
       " \"there is 1 man and 1 woman an then another man's arm\",\n",
       " 'i think so 1 eye is facing the camera']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# set the data subset to use\n",
    "subset = 1\n",
    "# load data\n",
    "data = json.load(open('../data/subsets/visdial_1.0_train_' +\n",
    "                 str(subset) + 'percent_subset.json'))['data']\n",
    "# load answers\n",
    "answers = data['answers']\n",
    "answers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove-6b-300d Model:\n",
      "Done. Glove-6b-300d with a vocabulary of 399998 words was loaded!\n"
     ]
    }
   ],
   "source": [
    "'''Loading Glove'''\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_glove_model(glove_file):\n",
    "    readable_name = \"-\".join(glove_file.rstrip('.txt').split('/')\n",
    "                             [-1].split(\".\")).capitalize()\n",
    "    print(f\"Loading {readable_name} Model:\")\n",
    "    df = pd.read_csv(glove_file, sep=\" \", quoting=3, header=None, index_col=0)\n",
    "    glove_model = {key: val.values for key, val in df.T.items()}\n",
    "    print(\n",
    "        f\"Done. {readable_name} with a vocabulary of {len(glove_model)} words was loaded!\")\n",
    "    return glove_model\n",
    "\n",
    "\n",
    "glove_6b_300 = load_glove_model('../embeddings/glove/glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Tokenize a sentence using a glove model, pass it through an LSTM and return the hidden state of each word'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sentence_to_hidden_state(sentence, glove_model, hidden_dim, batch_size):\n",
    "    # tokenize the sentence: words, punctuations are individual tokens\n",
    "    tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "    # get the glove vectors for each word\n",
    "    glove_vectors = []\n",
    "    for word in tokenized_sentence:\n",
    "        if word in glove_model:\n",
    "            glove_vectors.append(glove_model[word])\n",
    "        else:\n",
    "            glove_vectors.append(glove_model['unk'])\n",
    "    # create the input tensor\n",
    "    input_tensor = torch.FloatTensor(np.array(glove_vectors))\n",
    "    # pad the input tensor to 20 words if it is shorter, or truncate it if it is longer\n",
    "    if len(tokenized_sentence) < 20:\n",
    "        input_tensor = F.pad(input_tensor, (0, 0, 0, 20-len(tokenized_sentence)))\n",
    "    else:\n",
    "        input_tensor = input_tensor[:20]\n",
    "    # create the LSTM\n",
    "    lstm = nn.LSTM(300, hidden_dim)\n",
    "    # pass the input tensor through the LSTM and save the hidden state of each word\n",
    "    hidden_states = []\n",
    "    for i in range(len(tokenized_sentence)):\n",
    "        hidden_state, _ = lstm(input_tensor[:i+1].unsqueeze(1))\n",
    "        hidden_states.append(hidden_state[-1].detach().numpy().squeeze())\n",
    "    hidden_states = np.array(hidden_states)\n",
    "    # pass the hidden states of the sentence containing n words through a linear layer to get the final hidden state of 1*512\n",
    "    hidden_dim = hidden_states.shape[1]\n",
    "    linear = nn.Linear(hidden_dim, 512)\n",
    "    hidden_states = linear(torch.FloatTensor(hidden_states)).detach().numpy()\n",
    "    # max pool the hidden states to get the final hidden state of 1*512\n",
    "    hidden_states = np.max(hidden_states, axis=0)\n",
    "    return hidden_states\n",
    "\n",
    "'''Test the function'''\n",
    "sentence = \"This is a test sentence?\"\n",
    "hidden_states = sentence_to_hidden_state(sentence, glove_6b_300, 300, 1)\n",
    "hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268020/268020 [43:05<00:00, 103.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# create a pickle file to store the hidden states of the answers\n",
    "with open('../embeddings/answers/' + str(subset) + '/answer_embeddings.pkl', 'wb') as f:\n",
    "    for answer in tqdm(answers):\n",
    "        hidden_states = sentence_to_hidden_state(answer, glove_6b_300, 300, 1)\n",
    "        pickle.dump(hidden_states, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load the hidden states of the answers'''\n",
    "import pickle\n",
    "\n",
    "subset = 1\n",
    "# load the hidden states of the answers\n",
    "with open('../embeddings/answers/' + str(subset) + '/answer_embeddings.pkl', 'rb') as f:\n",
    "    answer_embeddings = []\n",
    "    while True:\n",
    "        try:\n",
    "            answer_embeddings.append(pickle.load(f))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268020, 512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "answer_embeddings = np.array(answer_embeddings)\n",
    "answer_embeddings.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('e2ecoref')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b1fdd7323491d7090a0fc5c93a5c5b1c35a699d6d70dae3f3df7c5ad3c8647a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
