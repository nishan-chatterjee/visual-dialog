{"positional arguments": {}, "help": null, "seed": 0, "config_name": "model_v10", "optional arguments": {"help": null, "seed": 0, "config_name": "model_v10"}, "dataset": {"v0.9": false, "overfit": false, "concat_hist": false, "max_seq_len": 20, "vocab_min_count": 5, "finetune": false, "is_add_boundaries": true, "is_return_options": true, "num_boxes": "fixed", "glove_path": "datasets/glove/embedding_Glove_840_300d.pkl", "train_feat_img_path": "datasets/bottom-up-attention/trainval_resnet101_faster_rcnn_genome__num_boxes_100_100.h5", "val_feat_img_path": "datasets/bottom-up-attention/val2018_resnet101_faster_rcnn_genome__num_boxes_100_100.h5", "test_feat_img_path": "datasets/bottom-up-attention/test2018_resnet101_faster_rcnn_genome__num_boxes_100_100.h5", "train_json_dialog_path": "datasets/annotations/visdial_1.0_train.json", "val_json_dialog_path": "datasets/annotations/visdial_1.0_val.json", "test_json_dialog_path": "datasets/annotations/visdial_1.0_test.json", "val_json_dense_dialog_path": "datasets/annotations/visdial_1.0_val_dense_annotations.json", "train_json_word_count_path": "datasets/annotations/visdial_1.0_word_counts_train.json"}, "model": {"decoder_type": "misc", "encoder_out": ["img", "ques"], "hidden_size": 512, "dropout": 0.1, "test_mode": false, "img_feat_size": 2048, "img_num_attns": null, "img_has_bboxes": true, "img_has_attributes": false, "img_has_classes": false, "txt_vocab_size": 11322, "txt_tokenizer": "nlp", "txt_bidirectional": true, "txt_embedding_size": 300, "txt_has_pos_embedding": true, "txt_has_layer_norm": true, "txt_has_decoder_layer_norm": true, "ca_has_shared_attns": false, "ca_has_proj_linear": false, "ca_has_layer_norm": true, "ca_has_residual": true, "ca_num_attn_stacks": 2, "ca_num_attn_heads": 4, "ca_pad_size": 2, "ca_has_avg_attns": false, "ca_has_self_attns": true}, "solver": {"optimizer": "adam", "adam_betas": [0.9, 0.997], "adam_eps": 1e-09, "weight_decay": 1e-05, "clip_norm": null, "num_epochs": 15, "batch_size": 8, "cpu_workers": 8, "batch_size_multiplier": 1, "scheduler_type": "LinearLR", "init_lr": 0.001, "min_lr": 1e-05, "num_samples": 123287, "warmup_factor": 0.2, "warmup_epochs": 1, "linear_gama": 0.5, "milestone_steps": [3, 5, 7, 9, 11, 13], "fp16": false}, "callbacks": {"resume": false, "validate": false, "path_pretrained_ckpt": null, "save_dir": "checkpoints", "log_dir": "checkpoints/tensorboard/"}}